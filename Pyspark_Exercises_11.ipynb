{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as f"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"46601c4a-7bdc-486d-9826-96f01c357d3b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession.builder.master(\"local[*]\").appName(\"Datamanipulation\").getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ad70430a-ae70-410a-8fd1-e66e05ecdeda","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stderr","text":["Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"]},{"output_type":"stream","output_type":"stream","name":"stdout","text":["22/10/26 08:50:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n22/10/26 08:50:59 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"]}],"execution_count":0},{"cell_type":"code","source":["spark"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"da6db9f3-170f-46a4-8a57-a647eac8647f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"execute_result","metadata":{},"execution_count":5,"output_type":"execute_result","data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://pedros-mbp.home:4041\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Datamanipulation</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f78b031f8e0>"]}}],"execution_count":0},{"cell_type":"code","source":["1 . # read our data - lives in a csv file\n\ndf = spark.read.csv('/FileStore/tables/Sample___EU_Superstore-1.csv',sep=',' ,header=True,inferSchema=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cfb5d3fb-a85e-42c5-bf19-5a188d96f059","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stderr","text":["                                                                                \r"]}],"execution_count":0},{"cell_type":"code","source":["df_loss=df.groupby(\"Discount\").sum(\"diff_sales\").orderBy(\"sum(diff_sales)\",ascending=False).limit(1)\ndf_loss.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":true,"cellMetadata":{},"nuid":"abda3696-6c6a-4677-8959-32a2beba7fbe","inputWidgets":{},"title":"# find the discount bracket which made us not gain the most (dynamically)"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f956a601-82fe-4e7e-803f-335047ff3da1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.9.7","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"Pyspark_Exercises_11","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
